import tkinter as tk
import customtkinter as ctk
import cv2
from PIL import Image, ImageTk, ImageSequence
import threading
import pygame
from ultralytics import YOLO
import time
import mediapipe as mp
from loguru import logger
from shared.utils import extend_bounding_box_area
from shared.driver_behavior_model import DriverBehaviorClassifier
from telegram.telegram_helper import send_driver_drowsiness_alert_from_frame

pygame.mixer.init()


def play_audio(file):
    def _play():
        pygame.mixer.music.load(file)
        pygame.mixer.music.play()

    threading.Thread(target=_play, daemon=True).start()


class DriverMonitorApp:
    def __init__(self, root):
        self.root = root
        self.root.title("Driver Alert System")
        self.root.geometry("920x700")
        self.root.configure(bg="#f4f4f4")

        self.init_variables()
        self.init_ui()
        self.load_gif()
        self.load_model()

    def load_model(self):
        self.yolo_model = YOLO("yolo11s.pt")
        # self.classifier = DriverBehaviorClassifier()
        self.classifier = DriverBehaviorClassifier("./models/cnn_based/mobilenet-cpu.h5")

    def init_variables(self):
        # Kh·ªüi t·∫°o Mediapipe Face
        self.mp_face = mp.solutions.face_detection

        # model_selection = 0: 0: short range, 1: long range
        self.face_detector = self.mp_face.FaceDetection(model_selection=0, min_detection_confidence=0.45)

        self.cap = cv2.VideoCapture(0)
        self.monitoring = False

        self.gif_frames = []
        self.gif_frame_index = 0
        self.is_gif_playing = True

        self.is_playing_warning = False
        self.last_phone_warning_time = 0
        self.warning_interval = 3

        self.last_boxes = []
        self.frame_count = 0
        self.frame_skip = 3
        self.start_time = time.time()

        self.yolo_predict_thread = None
        self.classifier_predict_thread = None
        self.frame_for_predict = None
        self.predict_lock = threading.Lock()

        self.sleepy_eye_count = 0
        self.sleepy_yawn_count = 0
        self.lookaway_count = 0
        self.phone_count = 0
        self.previous_status = "normal"

        self.using_phone = False

        # Tr·∫°ng th√°i kh√¥ng nh√¨n th·∫≥ng
        self.start_look_away_time = None
        self.play_look_away_sound_step = 1.5  # gi√¢y

        # Kh·ªüi t·∫°o th·ªùi gian g·ª≠i ·∫£nh qua Telegram
        self.last_send_time = None
        self.send_interval = 10  # gi√¢y
        self.telegram_frame = None  # ·∫£nh s·∫Ω g·ª≠i qua Telegram

        # Kh·ªüi t·∫°o v·ªÅ t√¨nh tr·∫°ng bu·ªìn ng·ªß
        self.start_sleepy_eye_time = None
        self.maximum_sleepy_eye_duration = 10  # gi√¢y
        self.warned_3s = False
        self.warned_5s = False
        self.warned_10s = False
        self.is_playing_stop_warning = False  # Th√¥ng b√°o d·ª´ng xe c√≥ ƒëang ph√°t hay kh√¥ng

    def init_ui(self):
        self.init_video_frame()
        self.init_status_panel()
        self.init_stat_panel()
        self.init_buttons()

    def init_video_frame(self):
        self.video_frame = tk.Label(self.root, bg="#ddd")
        self.video_frame.place(x=20, y=20, width=540, height=400)

    def init_status_panel(self):
        status_frame = tk.LabelFrame(self.root, text="Tr·∫°ng th√°i t√†i x·∫ø", font=("Helvetica", 14, "bold"), fg="#333")
        status_frame.place(x=580, y=20, width=320, height=100)

        self.status_label = tk.Label(status_frame, text="üü¢ B√¨nh th∆∞·ªùng", font=("Helvetica", 16), fg="green")
        self.status_label.pack(pady=20)

    def init_stat_panel(self):
        stat_frame = tk.LabelFrame(self.root, text="üìä Th·ªëng k√™ c·∫£nh b√°o", font=("Helvetica", 14))
        stat_frame.place(x=580, y=140, width=320, height=400)

        # Bu·ªìn ng·ªß
        tk.Label(stat_frame, text="üî¥ Bu·ªìn ng·ªß", font=("Helvetica", 13, "bold"), fg="red").pack(
            anchor="w", padx=10, pady=(5, 0)
        )
        self.eye_label = tk.Label(
            stat_frame, text="üëÅÔ∏è M·∫Øt bu·ªìn ng·ªß: 0", font=("Segoe UI Emoji", 12), fg="red", anchor="w"
        )
        self.eye_label.pack(fill="x", padx=20, pady=2)

        self.yawn_label = tk.Label(stat_frame, text="üò™ Ng√°p: 0", font=("Segoe UI Emoji", 12), fg="red", anchor="w")
        self.yawn_label.pack(fill="x", padx=20, pady=2)

        # M·∫•t t·∫≠p trung
        tk.Label(stat_frame, text="üü† M·∫•t t·∫≠p trung", font=("Helvetica", 13, "bold"), fg="orange").pack(
            anchor="w", padx=10, pady=(10, 0)
        )
        self.look_label = tk.Label(
            stat_frame, text="üëÄ Nh√¨n h∆∞·ªõng kh√°c: 0", font=("Helvetica", 12), fg="orange", anchor="w"
        )
        self.look_label.pack(fill="x", padx=20, pady=2)

        self.phone_label = tk.Label(
            stat_frame, text="üì± D√πng ƒëi·ªán tho·∫°i: 0", font=("Helvetica", 12), fg="orange", anchor="w"
        )
        self.phone_label.pack(fill="x", padx=20, pady=2)

    def init_buttons(self):
        self.start_icon = ctk.CTkImage(Image.open("./assets/start.png").resize((24, 24)))
        self.stop_icon = ctk.CTkImage(Image.open("./assets/stop.png").resize((24, 24)))

        self.start_button = ctk.CTkButton(
            master=self.root,
            text="Start",
            image=self.start_icon,
            compound="left",
            command=self.start_monitoring,
            fg_color="#4CAF50",
            hover_color="#45A049",
            text_color="white",
            corner_radius=10,
            font=("Arial", 12),
            width=100,
            height=36,
        )
        self.start_button.place(x=600, y=580)

        self.stop_button = ctk.CTkButton(
            master=self.root,
            text="Stop",
            image=self.stop_icon,
            compound="left",
            command=self.stop_monitoring,
            fg_color="#f44336",
            hover_color="#d32f2f",
            text_color="white",
            corner_radius=10,
            font=("Arial", 12),
            width=100,
            height=36,
        )
        self.stop_button.place(x=720, y=580)

        self.start_button.configure(state="normal")
        self.stop_button.configure(state="disabled")

    def load_gif(self):
        gif = Image.open("./assets/placeholder.gif")
        self.gif_frames = [ImageTk.PhotoImage(frame.copy().convert("RGBA")) for frame in ImageSequence.Iterator(gif)]
        self.play_gif()

    def play_gif(self):
        if self.is_gif_playing:
            frame = self.gif_frames[self.gif_frame_index]
            self.video_frame.config(image=frame)
            self.gif_frame_index = (self.gif_frame_index + 1) % len(self.gif_frames)
            self.root.after(100, self.play_gif)

    def start_monitoring(self):
        self.monitoring = True
        self.is_gif_playing = False
        self.start_button.configure(state="disabled")
        self.stop_button.configure(state="normal")
        self.update_frame()

    def stop_monitoring(self):
        self.monitoring = False
        self.is_gif_playing = True
        self.play_gif()
        self.start_button.configure(state="normal")
        self.stop_button.configure(state="disabled")

    def set_status(self, text, color):
        self.status_label.config(text=text, fg=color)

    def detect_and_crop_face(self, frame):
        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = self.face_detector.process(image_rgb)

        if results.detections:
            for detection in results.detections:
                ih, iw, _ = frame.shape
                bboxC = detection.location_data.relative_bounding_box
                x = int(bboxC.xmin * iw)
                y = int(bboxC.ymin * ih)
                w = int(bboxC.width * iw)
                h = int(bboxC.height * ih)

                x, y, w, h = extend_bounding_box_area(iw, ih, x, y, w, h, extension_ratio=1.2)

                face_crop = frame[y : y + h, x : x + w]
                return face_crop
        return None

    def run_predict_phone(self):
        self.yolo_predict_thread = None

        with self.predict_lock:
            results = self.yolo_model.predict(self.frame_for_predict, conf=0.6, classes=[67], verbose=False)
            self.last_boxes = []
            for box in results[0].boxes:
                x1, y1, x2, y2 = box.xyxy[0]
                conf = float(box.conf[0])
                self.last_boxes.append((x1, y1, x2, y2, conf))

            if self.last_boxes:
                self.using_phone = True
                self.set_status("üì± D√πng ƒëi·ªán tho·∫°i", "orange")
                self.phone_label.config(text=f"üì± D√πng ƒëi·ªán tho·∫°i: {self.phone_count}")
                now = time.time()
                logger.debug(f"Last phone warning time: {now - self.last_phone_warning_time}")
                if now - self.last_phone_warning_time > self.warning_interval:
                    self.phone_count += 1 if self.previous_status != "using_phone" else 0
                    self.previous_status = "using_phone"
                    play_audio("./assets/audios/not_use_phone.wav")
                    self.last_phone_warning_time = now
            else:
                self.using_phone = False

    def reset_warnings(self):
        self.start_sleepy_eye_time = None
        self.warned_3s = False
        self.warned_5s = False
        self.warned_10s = False

    def play_sleepy_eye_by_level(self):
        """
        X√°c ƒë·ªãnh √¢m thanh c·∫£nh b√°o d·ª±a tr√™n kho·∫£ng th·ªùi gian m√† m·∫Øt bu·ªìn ng·ªß ƒë√£ ƒë∆∞·ª£c ph√°t hi·ªán.
        """
        if self.start_sleepy_eye_time is None:
            self.start_sleepy_eye_time = time.time()

        duration = time.time() - self.start_sleepy_eye_time
        audio_path = "./assets/audios/warn_level2.wav" if not self.warned_3s else "./assets/audios/warn_level3.wav"
        is_warning_stop_car = False  # flag xem c√≥ ƒëang c·∫£nh b√°o stop_car_warning

        # C·ª© t·ª´ng chu k·ª≥ 6s s·∫Ω g·ª≠i ƒë·∫øn telegram
        now = time.time()
        if duration >= 6 and (self.last_send_time is None or now - self.last_send_time >= 6):
            self.last_send_time = now
            self.telegram_frame = self.frame_for_predict.copy()
            self.run_send_telegram_alert(duration)

        if duration >= 6 and not self.warned_5s:
            audio_path = "./assets/audios/stop_car_warning.wav"
            self.warned_5s = True
            is_warning_stop_car = True
        elif (duration >= 3 and not self.warned_3s) or (self.warned_3s and duration >= 7):
            audio_path = "./assets/audios/warn_level3.wav"
            self.warned_3s = True

        return audio_path, is_warning_stop_car

    def update_error_counts(self, labels):
        if "sleepy_eye" in labels:
            self.sleepy_eye_count += self.previous_status != "sleepy_eye"
            self.previous_status = "sleepy_eye"
            self.eye_label.config(text=f"üëÅÔ∏è M·∫Øt bu·ªìn ng·ªß: {self.sleepy_eye_count}")
        if "yawn" in labels:
            self.sleepy_yawn_count += self.previous_status != "yawn"
            self.previous_status = "yawn"
            self.yawn_label.config(text=f"üò™ Ng√°p: {self.sleepy_yawn_count}")
        if "look_away" in labels:
            self.lookaway_count += self.previous_status != "look_away"
            self.previous_status = "look_away"
            self.look_label.config(text=f"üëÄ Nh√¨n h∆∞·ªõng kh√°c: {self.lookaway_count}")

    def run_predict_classifier(self):
        """
        Ch·∫°y m√¥ h√¨nh ph√¢n lo·∫°i h√†nh vi l√°i xe tr√™n ·∫£nh ƒë√£ c·∫Øt t·ª´ khu√¥n m·∫∑t.
        """
        try:
            face_img = self.detect_and_crop_face(self.frame_for_predict)
            if face_img is not None:
                labels, _ = self.classifier.predict_from_image(face_img)
                self.post_process_predictions(labels)
                logger.info(f"Detected labels: {labels}")
        except Exception as e:
            logger.error(f"Prediction thread failed: {e}")
        finally:
            self.classifier_predict_thread = None  # cho ph√©p thread m·ªõi ch·∫°y ti·∫øp l·∫ßn sau

    def run_send_telegram_alert(self, lasted_duration):
        """
        G·ª≠i c·∫£nh b√°o qua Telegram n·∫øu t√†i x·∫ø nh·∫Øm m·∫Øt qu√° l√¢u.
        """
        if self.telegram_frame is not None:
            # T·∫°o thread g·ª≠i c·∫£nh b√°o
            threading.Thread(
                target=send_driver_drowsiness_alert_from_frame,
                args=(self.telegram_frame, lasted_duration),
                daemon=True,
            ).start()

    def post_process_predictions(self, labels):
        """
        X·ª≠ l√Ω k·∫øt qu·∫£ d·ª± ƒëo√°n t·ª´ m√¥ h√¨nh ph√¢n lo·∫°i h√†nh vi l√°i xe.
        Bao g·ªìm c·∫≠p nh·∫≠t tr·∫°ng th√°i, √¢m thanh c·∫£nh b√°o v√† th·ªëng k√™.
        """
        # Lo·∫°i b·ªè nh√£n 'natural'
        labels = [label for label in labels if label != "natural"]
        num_errors = len(labels)

        if num_errors == 0:
            self.reset_warnings()
            self.set_status("üü¢ T√¨nh tr·∫°ng b√¨nh th∆∞·ªùng", "green")
            self.previous_status = "normal"
            return

        # M·ª©c c·∫£nh b√°o m·∫∑c ƒë·ªãnh
        status_text = "üü† C·∫£nh b√°o nh·∫π"
        status_color = "orange"
        audio_path = "./assets/audios/warn_level1.wav"

        # Ph√¢n t√≠ch theo nh√£n
        if num_errors == 1:
            if "look_away" in labels:
                status_text = "üü† M·∫•t t·∫≠p trung"
                status_color = "orange"
                audio_path = "./assets/audios/look_straight.wav"

                # Ki·ªÉm tra xem c√≥ n√™n ph√°t audio y√™u c·∫ßu nh√¨n th·∫≥ng kh√¥ng?
                if (
                    self.start_look_away_time is None
                    or time.time() - self.start_look_away_time > self.play_look_away_sound_step
                ):
                    self.start_look_away_time = time.time()
                    play_audio(audio_path)

            elif "rub_eye" in labels:
                status_text = "üü† D·ª•i m·∫Øt - d·∫•u hi·ªáu m·ªát m·ªèi"
                status_color = "orange"
                audio_path = "./assets/audios/warn_level1.wav"
                play_audio(audio_path)
            elif "yawn" in labels:
                status_text = "üü† D·∫•u hi·ªáu bu·ªìn ng·ªß nh·∫π"
                status_color = "red"
                audio_path = "./assets/audios/warn_level2.wav"
                play_audio(audio_path)

            if "sleepy_eye" in labels:
                if self.start_sleepy_eye_time is None:
                    self.start_sleepy_eye_time = time.time()

                # Ki·ªÉm tra th·ªùi gian bu·ªìn ng·ªß
                audio_path, is_warning_stop_car = self.play_sleepy_eye_by_level()

                if is_warning_stop_car:
                    # N·∫øu ƒëang ph√°t c·∫£nh b√°o d·ª´ng xe r·ªìi
                    if not self.is_playing_stop_warning:
                        # N·∫øu ch∆∞a ph√°t th√¨ ph√°t v√† set tr·∫°ng th√°i ƒëang ph√°t
                        self.is_playing_stop_warning = True

                        def play_and_reset():
                            pygame.mixer.music.load(audio_path)
                            pygame.mixer.music.play()
                            while pygame.mixer.music.get_busy():
                                time.sleep(0.1)
                            self.is_playing_stop_warning = False

                        threading.Thread(target=play_and_reset, daemon=True).start()
                else:
                    # N·∫øu kh√¥ng ph·∫£i c·∫£nh b√°o d·ª´ng xe, m√† c·∫£nh b√°o stop_warning ƒëang ph√°t th√¨ ƒë·ª£i n√≥ xong
                    def play_warn3_when_ready():
                        while self.is_playing_stop_warning:
                            time.sleep(0.5)
                        play_audio(audio_path)

                    threading.Thread(target=play_warn3_when_ready, daemon=True).start()
        else:
            if "look_away" in labels:
                status_text = "üü£ M·∫•t t·∫≠p trung k√®m d·∫•u hi·ªáu bu·ªìn ng·ªß"
                status_color = "purple"
            else:
                status_text = "üî¥ Bu·ªìn ng·ªß nghi√™m tr·ªçng"
                status_color = "red"
            audio_path = "./assets/audios/warn_level3.wav"
            play_audio(audio_path)

        # C·∫≠p nh·∫≠t giao di·ªán v√† √¢m thanh c·∫£nh b√°o
        self.set_status(status_text, status_color)
        self.update_error_counts(labels)

    def update_frame(self):
        if self.monitoring:
            ret, frame = self.cap.read()
            if ret:
                frame = cv2.resize(frame, (540, 400))
                current_time = time.time()

                if current_time - self.start_time >= 3:
                    self.frame_count += 1
                    if self.frame_count % self.frame_skip == 0 and self.yolo_predict_thread is None:
                        self.frame_for_predict = frame.copy()
                        self.yolo_predict_thread = threading.Thread(target=self.run_predict_phone)
                        self.yolo_predict_thread.start()

                for x1, y1, x2, y2, conf in self.last_boxes:
                    cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)
                    cv2.putText(
                        frame,
                        f"Cell phone {conf:.2f}",
                        (int(x1), int(y1) - 10),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        0.6,
                        (0, 255, 0),
                        2,
                    )

                detect_interval = 1.0  # gi√¢y

                if not self.using_phone and (
                    not hasattr(self, "last_detect_time") or (current_time - self.last_detect_time) > detect_interval
                ):
                    face_img = self.detect_and_crop_face(frame)
                    if face_img is not None:
                        if self.classifier_predict_thread is None:
                            self.frame_for_predict = face_img.copy()
                            self.classifier_predict_thread = threading.Thread(target=self.run_predict_classifier)
                            self.classifier_predict_thread.start()
                    else:
                        logger.info("No face detected")

                        if (
                            self.start_look_away_time is None
                            or (current_time - self.start_look_away_time) > self.play_look_away_sound_step
                        ):
                            self.start_look_away_time = current_time
                            play_audio("./assets/audios/look_straight.wav")

                    self.last_detect_time = current_time  # c·∫≠p nh·∫≠t l·∫°i th·ªùi ƒëi·ªÉm detect cu·ªëi c√πng

                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                img = ImageTk.PhotoImage(Image.fromarray(frame_rgb))
                self.video_frame.configure(image=img)
                self.video_frame.image = img

            self.root.after(30, self.update_frame)

    def __del__(self):
        self.cap.release()
        if self.yolo_predict_thread and self.yolo_predict_thread.is_alive():
            self.yolo_predict_thread.join(timeout=1)

        if self.classifier_predict_thread and self.classifier_predict_thread.is_alive():
            self.classifier_predict_thread.join(timeout=1)
        pygame.mixer.quit()


if __name__ == "__main__":
    root = tk.Tk()
    app = DriverMonitorApp(root)
    root.mainloop()
